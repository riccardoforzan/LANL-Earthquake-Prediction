{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom sklearn.metrics import mean_absolute_error, max_error, mean_absolute_percentage_error\n\n#cross validation and hyperparameter optimization \nfrom sklearn.model_selection import GridSearchCV\n\n#for train and test dataset split\nfrom sklearn.model_selection import train_test_split\n\n#for feedforward neural network model\nfrom sklearn.neural_network import MLPRegressor\n\n#for data plots\nimport matplotlib.pyplot as plt\n","metadata":{"id":"3uyxEirwqTmg","outputId":"b3007e75-6132-4900-bd8f-52d73667a8d8","execution":{"iopub.status.busy":"2022-05-24T09:44:48.242439Z","iopub.execute_input":"2022-05-24T09:44:48.243224Z","iopub.status.idle":"2022-05-24T09:44:49.395764Z","shell.execute_reply.started":"2022-05-24T09:44:48.243101Z","shell.execute_reply":"2022-05-24T09:44:49.394611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Access to Kaggle LANL-Earthquake prediction dataset\nMore info:\nhttps://www.kaggle.com/c/LANL-Earthquake-Prediction","metadata":{}},{"cell_type":"code","source":"#Extract training data into from the kaggle dataset to a numpy representation\ndataset = pd.read_csv('../input/LANL-Earthquake-Prediction/train.csv', nrows=500000000, dtype={'acoustic_data': np.float64, 'time_to_failure': np.float64}).values\n\n#only for a check\nprint(dataset)\nprint(dataset.shape[0])\nprint(dataset.shape[1])","metadata":{"id":"-vTdR8qBcY2e","outputId":"91138185-6959-4820-bcf1-4ae5a9cde0c8","execution":{"iopub.status.busy":"2022-05-24T09:44:49.397651Z","iopub.execute_input":"2022-05-24T09:44:49.397993Z","iopub.status.idle":"2022-05-24T09:48:36.317706Z","shell.execute_reply.started":"2022-05-24T09:44:49.39795Z","shell.execute_reply":"2022-05-24T09:48:36.31493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions definition\nWe define some functions for creating the X matrix and Y vector. For the X matrix, we create it starting from the decided features. \nIn this case we use the following features scheme: for every segment we split it into a series of step, and then, for every segment we consider mean, std, min and max of the acoustic_signal value over the entire segment, over the last 100 steps and over the last 10 steps. We have at the end 12 features for every segment. ","metadata":{}},{"cell_type":"code","source":"#function for extracting features from the data, we extract the mean, standard deviation, max and min of the input vector\n#we can also try different statistical measures such that quantilies and so on\n\ndef extract_features(z):\n     return np.c_[z.mean(axis=0), \n                  z.std(axis=0),\n                  z.max(axis=0),\n                  z.min(axis=0),\n                #  np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=0)) .reshape(1,4)\n                 ]","metadata":{"id":"EnGgy-5AcRDU","execution":{"iopub.status.busy":"2022-05-24T09:48:36.319182Z","iopub.execute_input":"2022-05-24T09:48:36.319682Z","iopub.status.idle":"2022-05-24T09:48:36.325911Z","shell.execute_reply.started":"2022-05-24T09:48:36.31965Z","shell.execute_reply":"2022-05-24T09:48:36.324985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function for creating the labels vector\ndef createY(dataset, last_index=None, n_steps=150, step_length=1000):\n  segments= dataset.shape[0]//(n_steps*step_length)\n  y=np.ones(segments)\n  for i in range(0,segments):\n    y[i]=dataset[i*n_steps*step_length][1]\n  return y","metadata":{"id":"-niiY4xLhFZJ","execution":{"iopub.status.busy":"2022-05-24T09:48:36.32893Z","iopub.execute_input":"2022-05-24T09:48:36.329282Z","iopub.status.idle":"2022-05-24T09:48:36.341012Z","shell.execute_reply.started":"2022-05-24T09:48:36.329234Z","shell.execute_reply":"2022-05-24T09:48:36.340096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function for creating the training set with the decided features\n\ndef create_X(x, n_features, last_index=None, n_steps=150, step_length=1000):\n    segments= len(x)// (n_steps*step_length)\n\n    X_train = np.zeros((segments, n_features ), dtype= np.float64)\n    for i in range (0,segments):\n      seg = x[i*n_steps*step_length:i*n_steps*step_length+n_steps*step_length]\n      series = np.zeros((n_steps, step_length),  dtype= np.float64)\n      for j in range(0, n_steps):\n        series[j]=np.r_[seg[j*step_length:j*step_length+step_length]]\n      X_train[i] = np.r_[extract_features(series)[1],\n                 extract_features(series [ -10:])[1],\n                 extract_features(series [ -100:])[1]]\n    return X_train","metadata":{"id":"wYfSAoVxcSe0","execution":{"iopub.status.busy":"2022-05-24T09:48:36.350485Z","iopub.execute_input":"2022-05-24T09:48:36.3507Z","iopub.status.idle":"2022-05-24T09:48:36.359612Z","shell.execute_reply.started":"2022-05-24T09:48:36.350676Z","shell.execute_reply":"2022-05-24T09:48:36.358678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(y_train, y_pred):\n    plt.figure(figsize=(6, 6))\n    plt.scatter(y_train.flatten(), y_pred)\n    plt.xlim(0, 20)\n    plt.ylim(0, 20)\n    plt.xlabel('actual', fontsize=12)\n    plt.ylabel('predicted', fontsize=12)\n    plt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\n    plt.show()\n    \ndef score(y_train, y_pred):\n    y_train_flatten = y_train.flatten()\n    max = max_error(y_train_flatten, y_pred)\n    mae = mean_absolute_error(y_train_flatten, y_pred)\n    mape = mean_absolute_percentage_error(y_train_flatten, y_pred)\n    print(f'Max Error: {max:0.3f}')\n    print(f'Mean Absolute Error: {mae:0.3f}')\n    print(f'Mean Absolute Percentage Error: {mape:0.3f}')    ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:48:36.361245Z","iopub.execute_input":"2022-05-24T09:48:36.361712Z","iopub.status.idle":"2022-05-24T09:48:36.376271Z","shell.execute_reply.started":"2022-05-24T09:48:36.361673Z","shell.execute_reply":"2022-05-24T09:48:36.375506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING-VALIDATION-TEST Split of the Dataset\nWe subdivide the dataset into training and test set, and then we use cross validation on the training set for parameter tuning and model optimization","metadata":{}},{"cell_type":"code","source":"#CREATING THE TRAINING AND TEST SET\n\n#create the label vector\ny= createY(dataset)\n\n#create the X matrix\nX = create_X(dataset[:,0], n_features=12)\n\n#split X in X_train and X_test\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1, test_size=0.2)\n\n#for a check\nprint(X_train) \nprint(y_train)\n\n","metadata":{"id":"mHC40ZCXc4Eh","outputId":"56e14ab7-8cc0-41d5-fb10-1189fe821299","execution":{"iopub.status.busy":"2022-05-24T09:48:36.377387Z","iopub.execute_input":"2022-05-24T09:48:36.377875Z","iopub.status.idle":"2022-05-24T09:48:50.907532Z","shell.execute_reply.started":"2022-05-24T09:48:36.377828Z","shell.execute_reply":"2022-05-24T09:48:50.906528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training\nWe train 3 different Feedforward Neural Networks. \nWe consider the following activation functions:\n* ReLu\n* Sigmoid Activation Function (tanh)\n* Logitstic Regression\n\nand for every activation function we train different architectures. With the 5-Fold cross validation we manage to discover the best architecture for every activation function. After the training phase the output results and the predicted-true labels graphs are shown. ","metadata":{}},{"cell_type":"code","source":"#SETTING THE BEST LAYERS CONFIGURATION FOR THE MLPREGRESSOR BASED ON PRECEDENT STUDIES AND TRIALS WITH CROSS VALIDATION AND RELU ACTIVATION FUNCTION\n\n#MLPRegressor requires in input the parameter hidden_layer_sizes, that is a tuple specifying the number of \n#neurons in the hidden layers; for example: (10,) means that there is only 1 hidden layer with 10 neurons; \n#(10,50) means that there are 2 hidden layers, the first with 10 neurons, the second with 50 neurons\n\n#different hidder_layer configurations \nhl_parameters = {'hidden_layer_sizes': [(10,20,20,100), (20,20,20,100) , (20,20,20,20), (50,20,20,100), (100,20,20,100)] }\n\nmlp_cv = MLPRegressor(max_iter=200000, activation=\"relu\", solver='adam', tol=1e-4, random_state=1)\n\n#find best model using 5-fold CV and train it using all the training data\n \nmlp_grid = GridSearchCV(mlp_cv, hl_parameters, cv=5)  \n\n# fitting the model for grid search\nmlp_grid.fit(X_train, y_train)\n    \nprint ('RESULTS FOR NN\\n')\n\nprint(\"Best parameters set found:\")\nprint(mlp_grid.best_params_)\n\n#get training and test error for the best NN model from CV\n\nbest_mlp = mlp_grid.best_estimator_\n\n# fit the model on the entire training set\nbest_mlp.fit(X_train, y_train)\n\ntraining_error = 1. -best_mlp.score(X_train, y_train)\n\ntest_score = best_mlp.score(X_test, y_test)\n\nprint ('RESULTS FOR BEST NN\\n')\n\nprint (\"Best NN training error: %f\" % training_error)\nprint (\"Best NN test score: %f\" %test_score)\n","metadata":{"id":"oHUKFiakvUni","outputId":"dc9d02ef-f80c-4bf5-d7b2-8e306c9f9868","execution":{"iopub.status.busy":"2022-05-24T09:48:50.910857Z","iopub.execute_input":"2022-05-24T09:48:50.911283Z","iopub.status.idle":"2022-05-24T09:50:24.888396Z","shell.execute_reply.started":"2022-05-24T09:48:50.911234Z","shell.execute_reply":"2022-05-24T09:50:24.887437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred= best_mlp.predict(X_test)\n\nplot(y_test, y_pred)\n\nscore(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:50:24.890384Z","iopub.execute_input":"2022-05-24T09:50:24.899404Z","iopub.status.idle":"2022-05-24T09:50:25.190593Z","shell.execute_reply.started":"2022-05-24T09:50:24.899322Z","shell.execute_reply":"2022-05-24T09:50:25.189954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SETTING THE BEST LAYERS CONFIGURATION FOR THE MLPREGRESSOR BASED ON PRECEDENT STUDIES AND TRIALS WITH CROSS VALIDATION ANS SIGMOID ACTIVATION FUNCTION\n\n#MLPRegressor requires in input the parameter hidden_layer_sizes, that is a tuple specifying the number of \n#neurons in the hidden layers; for example: (10,) means that there is only 1 hidden layer with 10 neurons; \n#(10,50) means that there are 2 hidden layers, the first with 10 neurons, the second with 50 neurons\n\n#different hidder_layer configurations \nhl_parameters = {'hidden_layer_sizes': [(10,20,20,100), (20,20,20,100) , (20,20,20,20), (50,20,20,100), (100,20,20,100)] }\n\nmlp_cv = MLPRegressor(max_iter=200000, activation=\"tanh\", solver='adam', tol=1e-4, random_state=1)\n\n#find best model using 5-fold CV and train it using all the training data\n \nmlp_grid = GridSearchCV(mlp_cv, hl_parameters, cv=5)  \n\n# fitting the model for grid search\nmlp_grid.fit(X_train, y_train)\n    \nprint ('RESULTS FOR NN\\n')\n\nprint(\"Best parameters set found:\")\nprint(mlp_grid.best_params_)\n\n#get training and test error for the best NN model from CV\n\nbest_mlp = mlp_grid.best_estimator_\n\n# fit the model on the entire training set\nbest_mlp.fit(X_train, y_train)\n\ntraining_error = 1. -best_mlp.score(X_train, y_train)\n\ntest_score = best_mlp.score(X_test, y_test)\n\nprint ('RESULTS FOR BEST NN\\n')\n\nprint (\"Best NN training error: %f\" % training_error)\nprint (\"Best NN test score: %f\" %test_score)\n","metadata":{"id":"AiZQ5HnZ7dqG","outputId":"84630540-9d0e-4c01-dab6-7119b888f0c6","execution":{"iopub.status.busy":"2022-05-24T09:50:25.191641Z","iopub.execute_input":"2022-05-24T09:50:25.192197Z","iopub.status.idle":"2022-05-24T09:55:04.609324Z","shell.execute_reply.started":"2022-05-24T09:50:25.192118Z","shell.execute_reply":"2022-05-24T09:55:04.608183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred= best_mlp.predict(X_test)\n\nplot(y_test, y_pred)\n\nscore(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:55:04.611596Z","iopub.execute_input":"2022-05-24T09:55:04.612201Z","iopub.status.idle":"2022-05-24T09:55:04.855888Z","shell.execute_reply.started":"2022-05-24T09:55:04.612152Z","shell.execute_reply":"2022-05-24T09:55:04.85498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SETTING THE BEST LAYERS CONFIGURATION FOR THE MLPREGRESSOR BASED ON PRECEDENT STUDIES AND TRIALS WITH CROSS VALIDATION ANS LOGISTIC ACTIVATION FUNCTION \n\n#MLPRegressor requires in input the parameter hidden_layer_sizes, that is a tuple specifying the number of \n#neurons in the hidden layers; for example: (10,) means that there is only 1 hidden layer with 10 neurons; \n#(10,50) means that there are 2 hidden layers, the first with 10 neurons, the second with 50 neurons\n\n#different hidder_layer configurations \nhl_parameters = {'hidden_layer_sizes': [(10,20,20,100), (20,20,20,100) , (20,20,20,20), (50,20,20,100), (100,20,20,100)] }\n\nmlp_cv = MLPRegressor(max_iter=200000, activation=\"logistic\", solver='adam', tol=1e-4, random_state=1)\n\n#find best model using 5-fold CV and train it using all the training data\n \nmlp_grid = GridSearchCV(mlp_cv, hl_parameters, cv=5)  \n\n# fitting the model for grid search\nmlp_grid.fit(X_train, y_train)\n    \nprint ('RESULTS FOR NN\\n')\n\nprint(\"Best parameters set found:\")\nprint(mlp_grid.best_params_)\n\n#get training and test error for the best NN model from CV\n\nbest_mlp = mlp_grid.best_estimator_\n\n# fit the model on the entire training set\nbest_mlp.fit(X_train, y_train)\n\ntraining_error = 1. -best_mlp.score(X_train, y_train)\n\ntest_score = best_mlp.score(X_test, y_test)\n\nprint ('RESULTS FOR BEST NN\\n')\n\nprint (\"Best NN training error: %f\" % training_error)\nprint (\"Best NN test score: %f\" %test_score)\n","metadata":{"id":"Z-SIUJHKBqwR","outputId":"f64ae296-b1d3-469a-86c5-a8517334b150","execution":{"iopub.status.busy":"2022-05-24T09:55:04.857332Z","iopub.execute_input":"2022-05-24T09:55:04.858054Z","iopub.status.idle":"2022-05-24T09:58:28.047548Z","shell.execute_reply.started":"2022-05-24T09:55:04.858008Z","shell.execute_reply":"2022-05-24T09:58:28.046556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred= best_mlp.predict(X_test)\n\nplot(y_test, y_pred)\n\nscore(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:58:28.049507Z","iopub.execute_input":"2022-05-24T09:58:28.050854Z","iopub.status.idle":"2022-05-24T09:58:28.302695Z","shell.execute_reply.started":"2022-05-24T09:58:28.050793Z","shell.execute_reply":"2022-05-24T09:58:28.302047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
